{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages and Functions required\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling  import SMOTE\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "# Define the folder path containing CSV files\n",
    "folder_path = './../har70plus'\n",
    "\n",
    "# List to hold individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df_raw = pd.read_csv(file_path)\n",
    "        # Add a new column with the file name\n",
    "        df_raw['source_file'] = filename.replace('.csv','')\n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df_raw)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Convert date time to unix timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['unix_timestamp_ms'] = (df['timestamp'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp            0\n",
       "back_x               0\n",
       "back_y               0\n",
       "back_z               0\n",
       "thigh_x              0\n",
       "thigh_y              0\n",
       "thigh_z              0\n",
       "label                0\n",
       "source_file          0\n",
       "unix_timestamp_ms    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if any null value is present\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sepetrate out the target and features\n",
    "y = df.iloc[:,7:8]\n",
    "x = df[df.columns.difference(['label','timestamp']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets (80% training, 20% testing) -- Add stratification as target classes are imbalanced\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Splitting training set into training and validation sets (75% training, 25% validation) -- Add stratification as target classes are imbalanced\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1355757, 8), (451920, 8), (451920, 8), (2259597, 8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Shape------\n",
      "Shape     : (2259597, 10)\n",
      "Size      : 22595970\n",
      "Dimension : 2\n",
      "\n",
      "------Types------\n",
      "back_x               float64\n",
      "back_y               float64\n",
      "back_z               float64\n",
      "source_file           object\n",
      "thigh_x              float64\n",
      "thigh_y              float64\n",
      "thigh_z              float64\n",
      "unix_timestamp_ms      int64\n",
      "dtype: object\n",
      "\n",
      "------Head------\n",
      "           back_x    back_y    back_z source_file   thigh_x   thigh_y  \\\n",
      "1751225 -0.381592  0.109619  0.917236         515  0.034424  0.045166   \n",
      "2114166 -0.995361  0.064453 -0.018555         517 -0.941895 -0.047363   \n",
      "1526276 -0.866455 -0.076172 -0.139648         513 -0.525635  0.170654   \n",
      "1914772 -0.951172 -0.058838 -0.399414         516 -0.983643  0.191406   \n",
      "918631  -0.533936  0.056396 -0.272705         508 -0.704834  0.236572   \n",
      "\n",
      "          thigh_z  unix_timestamp_ms  \n",
      "1751225 -0.995850      1622109167299  \n",
      "2114166  0.138184      1623149583766  \n",
      "1526276  0.019287      1621597004619  \n",
      "1914772 -0.001465      1622469804180  \n",
      "918631   0.252197      1618585212324  \n",
      "\n",
      "------Tail------\n",
      "           back_x    back_y    back_z source_file   thigh_x   thigh_y  \\\n",
      "99379   -0.805908 -0.068848  0.515625         501 -0.204102 -0.203125   \n",
      "386640  -0.952881 -0.171631 -0.046387         504 -0.556641 -0.135498   \n",
      "176089  -0.988525 -0.161865 -0.166016         502 -0.955566 -0.007080   \n",
      "332612  -0.812500 -0.050293 -0.454834         503  0.161621  2.438232   \n",
      "1892594 -1.015381 -0.125244 -0.234619         516 -0.985352 -0.147949   \n",
      "\n",
      "          thigh_z  unix_timestamp_ms  \n",
      "99379   -1.045654      1616598934540  \n",
      "386640  -0.050049      1617791157419  \n",
      "176089  -0.358398      1616748475939  \n",
      "332612  -0.253662      1617031045479  \n",
      "1892594 -0.135986      1622469360619  \n",
      "\n",
      "------Missing Values------\n",
      "back_x               0\n",
      "back_y               0\n",
      "back_z               0\n",
      "source_file          0\n",
      "thigh_x              0\n",
      "thigh_y              0\n",
      "thigh_z              0\n",
      "unix_timestamp_ms    0\n",
      "dtype: int64\n",
      "\n",
      "------Duplicated Values------\n",
      "0\n",
      "\n",
      "------Unique Values------\n",
      "back_x                  8862\n",
      "back_y                  6436\n",
      "back_z                  8742\n",
      "source_file               18\n",
      "thigh_x                17483\n",
      "thigh_y                14875\n",
      "thigh_z                16206\n",
      "unix_timestamp_ms    1355757\n",
      "dtype: int64\n",
      "\n",
      "------Describe------\n",
      "                       count          mean           std           min  \\\n",
      "back_x             1355757.0 -8.700132e-01  2.690077e-01 -4.333252e+00   \n",
      "back_y             1355757.0 -3.308429e-02  1.510861e-01 -1.545166e+00   \n",
      "back_z             1355757.0  2.351573e-02  4.326698e-01 -2.066650e+00   \n",
      "thigh_x            1355757.0 -6.798582e-01  5.520352e-01 -7.691406e+00   \n",
      "thigh_y            1355757.0  2.745217e-03  2.736309e-01 -4.742432e+00   \n",
      "thigh_z            1355757.0 -3.841511e-01  5.126979e-01 -6.362061e+00   \n",
      "unix_timestamp_ms  1355757.0  1.619947e+12  2.179126e+09  1.616597e+12   \n",
      "\n",
      "                            25%           50%           75%           max  \n",
      "back_x            -9.929200e-01 -9.394530e-01 -8.281250e-01  3.630370e-01  \n",
      "back_y            -1.093750e-01 -2.172900e-02  5.078100e-02  1.576660e+00  \n",
      "back_z            -2.749020e-01 -1.123050e-01  3.125000e-01  1.177490e+00  \n",
      "thigh_x           -9.873050e-01 -9.357910e-01 -7.080100e-02  3.395264e+00  \n",
      "thigh_y           -1.166990e-01 -1.562500e-02  1.123050e-01  5.725098e+00  \n",
      "thigh_z           -9.860840e-01 -1.877440e-01 -3.906000e-03  3.953369e+00  \n",
      "unix_timestamp_ms  1.618326e+12  1.620376e+12  1.622108e+12  1.623410e+12  \n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "def check_df(data, head=5):\n",
    "    print(\"\\n------Shape------\")\n",
    "    print(f'Shape     : {df.shape}\\n'\n",
    "          f'Size      : {df.size}\\n'\n",
    "          f'Dimension : {df.ndim}')\n",
    "    print(\"\\n------Types------\")\n",
    "    print(data.dtypes)\n",
    "    print(\"\\n------Head------\")\n",
    "    print(data.head(head))\n",
    "    print(\"\\n------Tail------\")\n",
    "    print(data.tail(head))\n",
    "    print(\"\\n------Missing Values------\")\n",
    "    print(data.isnull().sum())\n",
    "    print(\"\\n------Duplicated Values------\")\n",
    "    print(data.duplicated().sum())\n",
    "    print(\"\\n------Unique Values------\")\n",
    "    print(data.nunique())\n",
    "    print(\"\\n------Describe------\")\n",
    "    print(data.describe().T)\n",
    "\n",
    "check_df(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out the num and cat features\n",
    "cat_cols = ['source_file']\n",
    "num_cols = [cols for cols in x.columns if cols not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1079312\n",
       "7     483452\n",
       "6     418055\n",
       "8     203182\n",
       "3      66058\n",
       "5       4978\n",
       "4       4560\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for imbalance in dataset\n",
    "y['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Feature Engineering\n",
    "\n",
    "# #use rf to get feature inportances\n",
    "# rf_classifier_fi = RandomForestClassifier(n_estimators=100, random_state=42, verbose=0)\n",
    "# rf_classifier_fi.fit(x_train, y_train)\n",
    "# feature_importance = rf_classifier_fi.feature_importances_\n",
    "# feature_importance_df = pd.DataFrame({'Feature':x_train.columns, 'Feature_importance':feature_importance}).sort_values(by='Feature_importance', ascending=False)\n",
    "# feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting fetaures who importance more tha 0.05\n",
    "x_train = x_train[x_train.columns.difference(['source_file'])]\n",
    "x_val = x_val[x_val.columns.difference(['source_file'])]\n",
    "x_test = x_test[x_test.columns.difference(['source_file'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Apply Random Forest to the data\n",
    "# # Define the parameter distributions\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(50, 100),     \n",
    "#     'max_depth': [None, 10, 20]\n",
    "# }\n",
    "\n",
    "# # Initialize the Random Forest classifier with class weights\n",
    "# rf_classifier = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# # Perform RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist, n_iter=10, cv=3, scoring='f1_weighted', random_state=42)\n",
    "# random_search.fit(x_train, y_train)\n",
    "\n",
    "# # Get the best parameters\n",
    "# best_params = random_search.best_params_\n",
    "# print(\"Best parameters:\", best_params)\n",
    "\n",
    "# # Get the best model\n",
    "# best_model = random_search.best_estimator_\n",
    "\n",
    "# # Evaluate the best model on the test set\n",
    "# predictions = best_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Random Forest to the data\n",
    "# Initialize your Random Forest model with class weights\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, verbose=0, class_weight='balanced')\n",
    "\n",
    "# Train the model on the selected features\n",
    "rf_classifier.fit(x_resampled, y_resampled)\n",
    "# Make predictions on the validation set\n",
    "predictions = rf_classifier.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9486059479553903\n",
      "Precision: 0.9594313675490554\n",
      "Recall: 0.9486059479553903\n",
      "F1-score: 0.9527433686734739\n",
      "ROC-AUC: 0.9960321060192917\n",
      "Confusion Matrix:\n",
      "[[203297   8564    261    474   3234     33      0]\n",
      " [  2374   9682     21     53   1081      0      0]\n",
      " [   156     15    701     31      8      1      0]\n",
      " [   278     38     16    650     13      0      0]\n",
      " [  2617   3860     30     38  77066      0      0]\n",
      " [    26      0      0      0      0  96664      1]\n",
      " [     0      0      0      0      0      3  40634]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with validation data\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_val, predictions, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_val, predictions, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_val, predictions, average='weighted')\n",
    "\n",
    "# Calculate ROC-AUC (for multiclass classification, you need to use one-vs-all strategy)\n",
    "roc_auc = roc_auc_score(y_val, rf_classifier.predict_proba(x_val), average='weighted', multi_class='ovr')\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# # Calculate class-wise accuracy\n",
    "# class_wise_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "# # Print class-wise accuracy\n",
    "# for i, accuracy in enumerate(class_wise_accuracy):\n",
    "#     print(f\"Class {i} Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9486568419189237\n",
      "Precision: 0.9591083797767159\n",
      "Recall: 0.9486568419189237\n",
      "F1-score: 0.9526717971544484\n",
      "ROC-AUC: 0.9959563283569196\n",
      "Confusion Matrix:\n",
      "[[203569   8287    274    479   3225     29      0]\n",
      " [  2458   9594     17     51   1092      0      0]\n",
      " [   167     17    697     24      7      0      0]\n",
      " [   281     22     22    665      6      0      0]\n",
      " [  2685   3952     33     41  76900      0      0]\n",
      " [    28      0      0      0      0  96660      2]\n",
      " [     0      0      0      0      0      4  40632]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with test data\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_test = rf_classifier.predict(x_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, predictions_test, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, predictions_test, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, predictions_test, average='weighted')\n",
    "\n",
    "# Calculate ROC-AUC (for multiclass classification, you need to use one-vs-all strategy)\n",
    "roc_auc = roc_auc_score(y_test, rf_classifier.predict_proba(x_test), average='weighted', multi_class='ovr')\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# # Calculate class-wise accuracy\n",
    "# class_wise_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "# # Print class-wise accuracy\n",
    "# for i, accuracy in enumerate(class_wise_accuracy):\n",
    "#     print(f\"Class {i} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_classify",
   "language": "python",
   "name": "ml_classify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
